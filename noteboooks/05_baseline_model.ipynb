{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8f0632",
   "metadata": {},
   "source": [
    "# Modelo Base para predicción \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241ce9e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "032ad4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import joblib \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#cargar dataset\n",
    "df = pd.read_csv('../data/pet_adoption_data.csv')\n",
    "\n",
    "#separar X e y\n",
    "y = df['TimeInShelterDays']\n",
    "X = df.drop(columns=['PetID', 'TimeInShelterDays', 'AdoptionLikelihood'])\n",
    "\n",
    "#Train/Test train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 42\n",
    ")\n",
    "\n",
    "#Cargar Preprocesador serializado\n",
    "preprocessor = joblib.load('../models/preprocessor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d3d4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de Evaluación \n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Devuelve MAE, RMSE y R2 para train y validation\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for name, X_set, y_set in [('train', X_train, y_train), ('val', X_val, y_val)]:\n",
    "        y_pred = model.predict(X_set)\n",
    "        mae = mean_absolute_error(y_set, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_set, y_pred))\n",
    "        r2 = r2_score(y_set, y_pred)\n",
    "        results[name] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "        print(f\"{name} metrics:\", results[name])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324d4fd",
   "metadata": {},
   "source": [
    "Evalúa un modelo para train y validación (test).\n",
    "\n",
    "Calcula 3 métricas:\n",
    "MAE → error absoluto promedio\n",
    "RMSE → error cuadrático medio, penaliza errores grandes\n",
    "R² → qué tan bien explica el modelo la variabilidad\n",
    "\n",
    "Devuelve un diccionario con resultados por conjunto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61d917",
   "metadata": {},
   "source": [
    "#### Entrenamiento de Modelos Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0d80a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics: {'MAE': 22.268411614117973, 'RMSE': np.float64(25.650293207132197), 'R2': 0.006826478417998771}\n",
      "val metrics: {'MAE': 22.25941504857843, 'RMSE': np.float64(25.717864756974002), 'R2': -0.002079654263464459}\n"
     ]
    }
   ],
   "source": [
    "#5.1 Linear Regression\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "lr_results = evaluate_model(lr_pipeline, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86ef3854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics: {'MAE': 0.0, 'RMSE': np.float64(0.0), 'R2': 1.0}\n",
      "val metrics: {'MAE': 30.497512437810947, 'RMSE': np.float64(37.6275938759778), 'R2': -1.1450890406826755}\n"
     ]
    }
   ],
   "source": [
    "#5.2 Decision Tree Regresor\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "dt_results = evaluate_model(dt_pipeline, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deda976",
   "metadata": {},
   "source": [
    "#### Comparación y Check de Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65656c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: {'train': {'MAE': 22.268411614117973, 'RMSE': np.float64(25.650293207132197), 'R2': 0.006826478417998771}, 'val': {'MAE': 22.25941504857843, 'RMSE': np.float64(25.717864756974002), 'R2': -0.002079654263464459}} Overfitting OK: True Diff=0.009\n",
      "Decision Tree: {'train': {'MAE': 0.0, 'RMSE': np.float64(0.0), 'R2': 1.0}, 'val': {'MAE': 30.497512437810947, 'RMSE': np.float64(37.6275938759778), 'R2': -1.1450890406826755}} Overfitting OK: False Diff=2.145\n"
     ]
    }
   ],
   "source": [
    "def check_overfitting(train_metrics, val_metrics, threshold=0.05):\n",
    "    \"\"\"Retorna True si la diferencia de R^2 entre train y val es menor a threshold\"\"\"\n",
    "    diff = abs(train_metrics['R2']- val_metrics['R2'])\n",
    "    return diff <= threshold, diff\n",
    "\n",
    "#Linear Regression\n",
    "lr_ok, lr_diff = check_overfitting(lr_results['train'], lr_results['val'])\n",
    "\n",
    "#Decision Tree\n",
    "dt_ok, dt_diff = check_overfitting(dt_results['train'], dt_results['val'])\n",
    "\n",
    "print(\"Linear Regression:\", lr_results, \"Overfitting OK:\", lr_ok, f\"Diff={lr_diff:.3f}\")\n",
    "print(\"Decision Tree:\", dt_results, \"Overfitting OK:\", dt_ok, f\"Diff={dt_diff:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec41ab8",
   "metadata": {},
   "source": [
    "#### Selección y Serialización del mejor modelo\n",
    "Elegimos el modelo con menor RMSE en validación que cumpla con el criterio de overfitting (diff <= 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01002b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: LinearRegression con RMSE=25.72\n",
      "Mejor modelo serializado en '../models/baseline_best_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "#Evaluar candidatos(modelos)\n",
    "candidates = []\n",
    "if lr_ok:\n",
    "    candidates.append(('LinearRegression', lr_pipeline, lr_results['val']['RMSE']))\n",
    "if dt_ok:\n",
    "    candidates.append(('DecisionTree', dt_pipeline, dt_results['val']['RMSE']))\n",
    "\n",
    "#Seleccionar el mejor modelo\n",
    "if candidates:\n",
    "    best_name, best_model, best_rmse = min(candidates, key=lambda x: x[2])\n",
    "    print(f\"Mejor modelo: {best_name} con RMSE={best_rmse:.2f}\")\n",
    "\n",
    "    #Serializar\n",
    "    joblib.dump(best_model, '../models/baseline_best_model.joblib')\n",
    "    print(\"Mejor modelo serializado en '../models/baseline_best_model.joblib'\")\n",
    "else:\n",
    "    print(\"Ningún modelo cumple el criterio de overfitting <5%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afdbd89",
   "metadata": {},
   "source": [
    "## Conclusión del Modelo Base\n",
    "\n",
    "- Se construyó un **modelo base (baseline)** para predecir `TimeInShelterDays` usando **Linear Regression** y **Decision Tree Regressor**.  \n",
    "- Se utilizó un **pipeline de preprocesamiento** que transforma automáticamente las variables categóricas, numéricas y binarias, asegurando consistencia entre entrenamiento y prueba.  \n",
    "- Ambos modelos fueron entrenados y evaluados en conjuntos de **train** y **test**, calculando las métricas **MAE, RMSE y R²**.  \n",
    "- Se verificó el **overfitting** comparando el R² de train y test, con un límite del 5%.  \n",
    "- Entre los modelos que cumplen el criterio de overfitting, se seleccionó el **mejor basado en menor RMSE en validación**.  \n",
    "- En este caso, el **Linear Regression** resultó ser el mejor modelo con RMSE = 25.72 y fue **serializado** para uso posterior en producción (`baseline_best_model.joblib`).  \n",
    "\n",
    "**Resumen:**  \n",
    "El pipeline garantiza un preprocesamiento consistente, las métricas permiten evaluar desempeño y overfitting, y la selección final asegura que el modelo elegido sea confiable y generalizable a nuevos datos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyect-v-regression-team3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
